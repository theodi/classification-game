<section id="evaluation" class="hidden">
    <div id='evaluation-set' class="invisbox-small">
      <div id="buttons" style="width: 100%">
        <h3 id="evaluationStatus">Click the button below to evaluate your model and obtain a score</h3>
        <button type="button" id="evaluationButton" name="evaluation-button" onClick="autoEvaluate(1);">Evaluate model</button>
      </div>
      <div id="results" class="results">
        <table>
          <tr>
            <th>Player</th>
            <th>Confidence in model</th>
            <th style="width:240px;">&nbsp;</th>
            <th>Score<br/>(run 1)</th>
            <th>Score<br/>(run 2)</th>
            <th>Score<br/>(run 3)</th>
            <th>Score<br/>(run 4)</th>
          </tr>
          <tr>
            <td>You</td>
            <td id="confidence-user"></td>
            <td style="text-align: right;">% correctly classified (a)<br>Difference from confidence (b)<br>Score (a - b)</td>
            <td id="result1-user"></td>
            <td id="result2-user"></td>
            <td id="result3-user"></td>
            <td id="result4-user"></td>
          </tr>
          <tr>
            <td>vs Machine</td>
            <td id="confidence-stoopid-ai"></td>
            <td>&nbsp;</td>
            <td id="result1-stoopid-ai"></td>
            <td id="result2-stoopid-ai"></td>
            <td id="result3-stoopid-ai"></td>
            <td id="result4-stoopid-ai"></td>
          </tr>
          <tr>
            <td>vs Human+ML</td>
            <td id="confidence-hybrid"></td>
            <td>&nbsp;</td>
            <td id="result1-hybrid"></td>
            <td id="result2-hybrid"></td>
            <td id="result3-hybrid"></td>
            <td id="result4-hybrid"></td>
          </tr>
          <tr>
            <td>Total</td>
            <td>&nbsp;</td>
            <td>&nbsp;</td>
            <td id="result1-score"></td>
            <td id="result2-score"></td>
            <td id="result3-score"></td>
            <td id="result4-score"></td>
          </tr>
        </table>
      </div>
      <div class="expandable-box">
        <h1><strong>How evaluation works?</strong></h1>
        <span class="expand-button" onclick="toggleContent(this)">+</span>
        <div class="hidden-content">
            <div style="width: 50%; margin-left: auto; margin-right: auto; padding-top: 30%; position:relative;"><iframe src="https://player.vimeo.com/video/888716255?h=eed4b93e93&amp;badge=0&amp;autopause=0&amp;player_id=0&amp;app_id=58479" frameborder="0" allow="autoplay; fullscreen; picture-in-picture" style="position:absolute;top:0;left:0;width:100%;height:100%;" title="Machine Learning Game Video Two"></iframe></div><script src="https://player.vimeo.com/api/player.js"></script>
            <p>When you click "Evaluate model," four sets of 20 cards, each containing unknown cities, will be selected and classified in four separate runs.</p>
            <h4><strong>1. Accuracy Against Your Confidence</strong></h4>
            <p>During training, you created a tree that was evaluated against the training data. All properties correctly classified in this set contribute to your confidence, which is displayed as a percentage of the evaluation set you expect to correctly classify. Your score here is calculated as the percentage of correctly classified items minus the difference from your confidence.</p>
            <h4><strong>2. vs Machine: Comparing to an Overfitted Model</strong></h4>
            <p>If your model can outperform an overfitted machine model (with a claimed accuracy of 100%), you gain points. However, if your model performs worse, you lose points.</p>
            <h4><strong>3. vs Human+ML: Competing with a Human-Advised Machine</strong></h4>
            <p>If your model outperforms a machine that has been guided by a human to avoid overfitting, you earn a substantial number of points. You lose fewer points if you don't surpass this machine's performance.</p>
        </div>
      </div>
    </div>
</section>